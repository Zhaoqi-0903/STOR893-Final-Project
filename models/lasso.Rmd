---
title: "lasso_ridge_svm"
author: "Wan Zhang"
date: "5/4/2021"
output: html_document
---

```{r, setup, include=FALSE}
# knitr::opts_knit$set(root.dir = "/Users/zhangwan/OneDrive - University of North Carolina at Chapel Hill/893/STOR893-Final-Project-")
```

```{r}
# setwd("/Users/zhangwan/OneDrive - University of North Carolina at Chapel Hill/893/STOR893-Final-Project-")
load("../Data/merge_df.RData")

load("../Data/oversampling_df.RData")


# df_dep<-df[,c(1:121,251)]
# df_dep<-na.omit(df_dep) #1028 obs
# df_dep_sorted<-df_dep
# df_dep_sorted$Trait_130<-as.factor(ifelse(df_dep_sorted$Trait_130==1,0,1))
# df_dep_sorted<-df_dep_sorted[order(df_dep_sorted$Trait_130),]
# 
# table(df_dep_sorted$Trait_130)
# #95 obs have experienced a diagnosed DSMIV Major Depressive Episode over his/her lifetime among 1028 obs
# #imbalancedRatio
# imbalanceRatio(df_dep_sorted,"Trait_130")
# 
# # generate 500 synthetic data
# set.seed(893)
# df_dep_RWO <- mwmote(df_dep_sorted, numInstances = 500, classAttr="Trait_130")
# df_dep_oversampling<-rbind(df_dep_sorted,df_dep_RWO)
# #df_dep_oversampling<-df_dep_oversampling[,-1]#remove the subjectID
# 
# #plot the difference between original dataset and oversampling dataset by using the first two FC feature scores and first two SC feature scores
# plotComparison(df_dep_sorted, df_dep_oversampling, attrs = names(df_dep_oversampling)[2:3], classAttr = "Trait_130")
# plotComparison(df_dep_sorted, df_dep_oversampling, attrs = names(df_dep_oversampling)[62:63], classAttr = "Trait_130")

```

```{r}
library(glmnet)
library(ROCR)
library(caret)

glmnet_mod = function(df,index_trait = 1, alpha, mod.family, feature = "all"){
  if(feature == "fc"){
    df_na_omit = cbind(df[,c(2:61)], df[,121+index_trait])
  }else if(feature == "sc"){
    df_na_omit = cbind(df[,c(62:121)], df[,121+index_trait])
  }else{
    df_na_omit = cbind(df[,c(2:121)], df[,121+index_trait])
  }
  
  #  if(feature == "fc"){
  #   df_na_omit = cbind(df[,c(2:61)], df[,122])
  # }else if(feature == "sc"){
  #   df_na_omit = cbind(df[,c(62:121)], df[,122])
  # }else{
  #   df_na_omit = cbind(df[,c(2:121)], df[,122])
  # }

  colnames(df_na_omit)[dim(df_na_omit)[2]] = "Depressive_Ep"
  df_na_omit = na.omit(df_na_omit)

  index = sample(c(1:dim(df_na_omit)[1]), round(dim(df_na_omit)[1]/3))

  df_train = df_na_omit[-index,]
  df_test = df_na_omit[index,]

  # if(mod.family == "binomial"){
  #   y_trn = matrix(ifelse(df_train[,ncol(df_train)] == 1, 0, 1))
  #   y_tst = matrix(ifelse(df_test[,ncol(df_test)] == 1, 0, 1))
  # }else{
  #   y_trn = matrix(df_train[,ncol(df_train)])
  #   y_tst = matrix(df_test[,ncol(df_test)])
  # }
  
  y_trn = matrix(as.numeric(df_train[,ncol(df_train)])) - 1
  y_tst = matrix(as.numeric(df_test[,ncol(df_test)])) - 1
  x_trn = model.matrix(Depressive_Ep~., df_train)[,-1]
  x_tst = model.matrix(Depressive_Ep~., df_test)[,-1]
  cvfit=cv.glmnet(x_trn,y_trn)
  mod = glmnet(x_trn, y_trn, family = mod.family, alpha = alpha, lambda = cvfit$lambda.min)
  mod.pred = predict(mod, x_tst, type = "response")

  if(mod.family == "binomial"){
    predictions <- prediction(mod.pred,y_tst)
    plot(unlist(performance(predictions, "sens")@x.values), unlist(performance(predictions, "sens")@y.values),
         type="l", lwd=2, ylab="Sensitivity", xlab="Cutoff")
    par(new=TRUE)
    plot(unlist(performance(predictions, "spec")@x.values), unlist(performance(predictions, "spec")@y.values),
         type="l", lwd=2, col='red', ylab="", xlab="")
    # axis(4, at=seq(0,1,0.2),labels=z)
    mtext("Specificity",side=4, padj=-2, col='red')
  
    sens = cbind(unlist(performance(predictions, "sens")@x.values), unlist(performance(predictions, "sens")@y.values))
    spec = cbind(unlist(performance(predictions, "spec")@x.values), unlist(performance(predictions, "spec")@y.values))
    threshold = sens[which.min(apply(sens, 1, function(x) min(colSums(abs(t(spec) - x))))), 1]
  
    conf.mat = confusionMatrix(data = factor(ifelse(mod.pred > threshold, 1, 0)), reference = factor(y_tst))
  }else{
    threshold = NULL
    conf.mat = NULL
  }
  

  return(list(mod = mod, predict = mod.pred, err = mean((y_tst-mod.pred)^2), threshold = threshold, confusion.matrix = conf.mat$table, ratio = conf.mat$byClass))
}
```

## LASSO for 130

```{r}
set.seed(15)
mod.lasso.130.sc = glmnet_mod(df_dep_oversampling, alpha=1, mod.family = "binomial", feature = "sc")
# lasso model with only sc
mod.lasso.130.sc$mod
# confusion matrix
mod.lasso.130.sc$confusion.matrix
# Sensitivity          Specificity 
mod.lasso.130.sc$ratio
# mse
mod.lasso.130.sc$err

mod.lasso.130.fc = glmnet_mod(df_dep_oversampling, alpha=1, mod.family = "binomial", feature = "fc")
# lasso model with only fc
mod.lasso.130.fc$mod
# confusion matrix
mod.lasso.130.fc$confusion.matrix
# Sensitivity          Specificity 
mod.lasso.130.fc$ratio
# mse
mod.lasso.130.fc$err

# doesn't work
mod.lasso.130.all = glmnet_mod(df_dep_oversampling, alpha=1, mod.family = "binomial", feature = "all")
# lasso model will all features
mod.lasso.130.all$mod
# confusion matrix
mod.lasso.130.all$confusion.matrix
# Sensitivity          Specificity 
mod.lasso.130.all$ratio
# mse
mod.lasso.130.all$err
```

LASSO for trait 130 sometimes shrinks to 0. So we pick a smaller alpha to keep more predictors.

```{r}
set.seed(15)
mod.lasso.130.sc = glmnet_mod(df_dep_oversampling, alpha=0.8, mod.family = "binomial", feature = "sc")
# lasso model with only sc
mod.lasso.130.sc$mod
# confusion matrix
mod.lasso.130.sc$confusion.matrix
# Sensitivity          Specificity 
mod.lasso.130.sc$ratio
# mse
mod.lasso.130.sc$err

mod.lasso.130.fc = glmnet_mod(df_dep_oversampling, alpha=0.8, mod.family = "binomial", feature = "fc")
# lasso model with only fc
mod.lasso.130.fc$mod
# confusion matrix
mod.lasso.130.fc$confusion.matrix
# Sensitivity          Specificity 
mod.lasso.130.fc$ratio
# mse
mod.lasso.130.fc$err

mod.lasso.130.all = glmnet_mod(df_dep_oversampling, alpha=0.8, mod.family = "binomial", feature = "all")
# lasso model will all features
mod.lasso.130.all$mod
# confusion matrix
mod.lasso.130.all$confusion.matrix
# Sensitivity          Specificity 
mod.lasso.130.all$ratio
# mse
mod.lasso.130.all$err
```

## LASSO for 131

```{r}
mod.lasso.131.sc = glmnet_mod(df, index_trait = 131, alpha = 1, mod.family = "gaussian", feature = "sc")
# lasso model with only sc
mod.lasso.131.sc$mod
# mse
mod.lasso.130.sc$err

mod.lasso.131.fc = glmnet_mod(df, index_trait = 131, alpha = 1, mod.family = "gaussian", feature = "fc")
# lasso model with only fc
mod.lasso.131.fc$mod
# mse
mod.lasso.131.fc$err


mod.lasso.131.all = glmnet_mod(df, index_trait = 131, alpha = 1, mod.family = "gaussian", feature = "all")
# lasso model will all features
mod.lasso.131.all$mod
# mse
mod.lasso.131.all$err
```

## Ridge for 130

```{r}
mod.ridge.130.sc = glmnet_mod(df_dep_oversampling, alpha = 0, mod.family = "binomial", feature = "sc")
# ridge model with only sc
mod.ridge.130.sc$mod
# confusion matrix
mod.ridge.130.sc$confusion.matrix
# Sensitivity          Specificity 
mod.ridge.130.sc$ratio
# mse
mod.ridge.130.sc$err


mod.ridge.130.fc = glmnet_mod(df_dep_oversampling, alpha = 0, mod.family = "binomial", feature = "fc")
# ridge model with only fc
mod.ridge.130.fc$mod
# confusion matrix
mod.ridge.130.fc$confusion.matrix
# Sensitivity          Specificity 
mod.ridge.130.fc$ratio
# mse
mod.ridge.130.fc$err


mod.ridge.130.all = glmnet_mod(df_dep_oversampling, alpha = 0, mod.family = "binomial", feature = "all")
# ridge model with all features
mod.ridge.130.all$mod
# confusion matrix
mod.ridge.130.all$confusion.matrix
# Sensitivity          Specificity 
mod.ridge.130.all$ratio
# mse
mod.ridge.130.all$err

```

## Ridge for 131

```{r}
mod.ridge.131.sc = glmnet_mod(df, index_trait = 131, alpha = 0, mod.family = "gaussian", feature = "sc")
# ridge model with only sc
mod.ridge.131.sc$mod
# mse
mod.ridge.131.sc$err


mod.ridge.131.fc = glmnet_mod(df, index_trait = 131, alpha = 0, mod.family = "gaussian", feature = "fc")
# ridge model with only fc
mod.ridge.131.fc$mod
# mse
mod.ridge.131.fc$err


mod.ridge.131.all = glmnet_mod(df, index_trait = 131, alpha = 0, mod.family = "gaussian", feature = "all")
# ridge model with all features
mod.ridge.131.all$mod
# mse
mod.ridge.131.all$err

```

## SVM

```{r}
library(e1071)
svm.fit = function(df, index_trait = 1, type = "C-classification", feature = "all"){
   if(feature == "fc"){
    df.svm = cbind(df[,c(2:61)], df[,121+index_trait])
  }else if(feature == "sc"){
    df.svm = cbind(df[,c(62:121)], df[,121+index_trait])
  }else{
    df.svm = cbind(df[,c(2:121)], df[,121+index_trait])
  }

  colnames(df.svm)[dim(df.svm)[2]] = "Depressive_Ep"
  df.svm = na.omit(df.svm)
  # if(type == "C-classification"){
  #   df.svm$Depressive_Ep = ifelse(df.svm$Depressive_Ep == 1, 0, 1)
  # }

  index = sample(c(1:dim(df.svm)[1]), round(dim(df.svm)[1]/3))

  df_train = df.svm[-index,]
  df_test = df.svm[index,]

  # mod.svm = svm(Depressive_Ep~., data = df_train, type = "C-classification", kernel = "radial", cost = 50000, C = 150)
  if(feature == "fc"){
    mod.svm = svm(Depressive_Ep~FCfeature_1+FCfeature_2+FCfeature_3, data = df_train, kernel="radial", type = type, cost = 1000)
    summary(mod.svm)
    svm.pred = predict(mod.svm, df_test[,c(1:3)])
  }else if(feature == "sc"){
    mod.svm = svm(Depressive_Ep~SCfeature_1+SCfeature_2+SCfeature_3, data = df_train, kernel="radial", type = type, cost = 1000)
    summary(mod.svm)
    svm.pred = predict(mod.svm, df_test[,c(1:3)])
  }else{
    mod.svm = svm(Depressive_Ep~FCfeature_1+FCfeature_2+FCfeature_3+SCfeature_1+SCfeature_2+SCfeature_3, data = df_train, kernel="radial", type = type, cost = 1000)
    summary(mod.svm)
    # svm.pred = predict(mod.svm, df_test[-dim(df_test)[2]])
    svm.pred = predict(mod.svm, df_test[,c(1:3, 61:63)])
  }

  if(type == "C-classification"){
    (svm.table<-table(svm.pred,df_test$Depressive_Ep))
    conf.mat = confusionMatrix(svm.table)
    mse = NULL
  }else{
    conf.mat = NULL
    mse = mean((svm.pred - df_test$Depressive_Ep)^2)
  }

  return(list(mod = mod.svm, confusion.matrix = conf.mat$table, ratio = conf.mat$byClass, mse = mse))
}


```

## SVM for 130

```{r}
svm.fit(df_dep_oversampling)
svm.fit(df_dep_oversampling, feature = "sc")
svm.fit(df_dep_oversampling, feature = "fc")
```

## SVM for 131

```{r}
svm.fit(df, index_trait = 131, type = "eps-regression")
svm.fit(df, index_trait = 131, type = "eps-regression", feature = "sc")
svm.fit(df, index_trait = 131, type = "eps-regression", feature = "fc")
```

